---
title: '(論文紹介)Zhou, Zongwei, et al. "Models genesis." Medical image analysis 67 (2021): 101840.'
date: "2023-03-21"
category:
tags:
  - paper
  - medical
  - deep learning
  - representation learning
---

# どんな論文なのか？
医用画像(3D)に対して表現学習を適用した論文です。
これまでの表現学習のフレームワークは2Dやclassification (encoder)をメインターゲットにしていました。
一方、この論文では3Dやsegmentationをターゲットにして新しい表現学習のフレームワーク(Models Genesis)を提案しています。
このフレームワークの基本的なアイデアは、様々な方法で変換した画像から元画像を復元することで解剖学的な形状を学習し、有用な特徴を獲得しようというものです。
著者が行った検証実験においては、他の事前学習の手法やscratchからの学習と比較して、様々な臓器やモダリティにおいて推論精度が良くなったとしています。

<figure>
<center>
<img src="https://github.com/MrGiovanni/ModelsGenesis/blob/master/figures/framework.png?raw=true" alt="Framework of Models Genesis" width="100%"/>
<figcaption>Framework of Models Genesis</figcaption>
</center>
</figure>

# 先行研究と比べてどうか？
<!-- この論文では2D画像で使われる通常の表現学習をそのまま3Dの医用画像に適用するのは以下の理由から適切ではないと主張しています。 -->
<!-- - タスクが簡単すぎて意味のある特徴を学習できない -->
<!-- - 下流タスクと無関係な特徴を学習してしまう可能性が高い -->
これまでの研究では3Dの画像を2Dに次元を下げて学習させるのが一般的でした。
このアプローチだと3Dの情報が欠落してしまうので精度に限界がありました。
一方、3Dのまま学習させようとすると、アノテーションコストが高いため大規模なデータセットを用意するのが難しいという課題があります。
この論文では、これらの問題点に対処するために3Dの表現学習のフレームワークを提案しています。

著者が挙げているこの論文のcontributionは以下の3点です。
- 様々な病気、臓器、モダリティに使える汎用的な3Dの事前学習済みモデルのコレクション[^1]
- 分類タスクにはエンコーダー部分を、セグメンテーションタスクにはエンコーダー・デコーダー部分を活用できる自己教師あり学習のフレームワーク
- 複数の観点からロバストな特徴量を学習するための自己教師あり学習の手法

# どのような技術を使っているのか？

この論文で提案している表現学習の手順は以下の通りです。
1. 3D画像からsub-volumeを切り出す
2. sub-volumeに以下の変換をある確率で実施する
   - ベジェ曲線を使った信号値の非線形変換
   - 近傍ピクセルをシャッフルする変換
   - 外側領域または内側領域のcutout
3. 変換後の画像をEncoder-Decoderモデルの入力とし、Decoderの出力が変換前の元画像となるように学習させる

# 結論を導くための結果は何か？
著者の検証実験では、複数のタスクで他手法との比較を実施して、どのタスクでも最も良い精度か最も良いものとほぼ同等の精度がでることを確認しています。

<figure>
<center>
<img src="https://github.com/MrGiovanni/ModelsGenesis/blob/master/figures/results.png?raw=true" alt="Comparison with other methods" width="80%"/>
<figcaption>Comparison with other methods</figcaption>
</center>
</figure>

# どのような議論がされていたか？
## 医療画像版ImageNetは必要か？
自然画像ではImageNetで事前学習したモデルがどの自己教師あり学習の手法で学習したモデルよりも精度が良くなっていおり、
医療画像でも同様に大量のアノテーション済みデータを使用した事前学習をしたほうが良い精度が出るのではと考えられます。
ただし、現実的にアノテーション済みの3Dデータを大量に用意することは難しく、しばらくは自己教師あり学習の手法に頼ることが必要そうです、

## 同一ドメインまたはクロスドメインのどちらが転移学習ではよいのか?
同一ドメインのデータが大量にある場合は同一ドメインのほうが好ましいですが、
この論文で提案したフレームワークで事前学習したモデルはクロスドメインで使用しても良い精度がでると、著者は主張しています。

# この研究のメリットデメリットは？
以下のようなメリット・デメリットが考えられます。
## メリット
- エンコーダーだけでなくデコーダーも事前学習できること
- (ChestCTで)事前学習済みのモデルをモダリティ(CT/MRI)を問わず使用できること
- 大きなバッチサイズなどを前提にしておらず、一般的なマシンリソースで学習できること

## デメリット
- 学習時のデータ拡張が最適化わからない、パラメータ調整が必要な可能性あり


[^1]: 著者が作成した事前学習済みモデル（keras, pytorch）はGithubに利用手順が記載されています([関連Issue](https://github.com/MrGiovanni/ModelsGenesis/issues/22 ) )
