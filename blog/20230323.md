---
title: '(論文紹介)Tang, Yucheng, et al. "Self-supervised pre-training of swin transformers for 3d medical image analysis." Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.'
date: "2023-03-23"
category:
tags:
    - paper
    - medical
    - deep learning
    - vision transformer
    - representation learning
---

# どんな論文なのか？
医用画像(3D)に対してSwin transformerと事前学習を適用した論文です。
この論文では大きく以下の2つの手法を提案しています。
- Swin UNETRという3D向けのTransformerモデル（このモデルは自己教師ありの事前学習向けの階層的なエンコーダーを持っています）
- 人体の解剖学的なパターンを学習するための事前学習タスク(proxy task)

著者の行った実証実験では5050枚の公開されているCT画像を使用して事前学習を行っています。
BTCVというコンペティションでそのモデルをfine-tuningした結果、public leaderboardで最も良い精度を達成したと報告しています。

# 先行研究と比べてどうか？
最近の研究により、ViT(Vision Transformer)がCNNベースのモデルを超えてSOTAの精度を達成することが報告されています。
これはTransformerがImageNetなどでの事前学習によって、CNNに比べてより強力な特徴量を学習できるためと考えられます。
しかし、医療画像と一般自然画像はドメインが大きく異なるため、既存の事前学習済みモデルをそのまま適用することは難しいです。
また、CTやMRIの画像は3Dデータのため、2Dモデルだと3次元情報が欠落してしまいます。
本論文では、これらの課題に対処するために上記の提案を行っています。

これまでにも医療画像に対してTransformerを適用した手法が提案されていましたが、
CNNベースのモデルにtransformer blockを追加するといった程度で、Transformerを十分に活用したものではありませんでした。
一方、本論文の提案モデルはEncoderはすべてTransformerで構成されておりTransformer主体のモデルと言えます。

また、Swin Transformerの活用についても、これまでの論文は2Dの医療画像を対象としていましたが、
本論文ではそれを3D画像に適用できるようにしています。

# どのような技術を使っているのか？
## モデル構成
Swin UNETRはSwin TransformerによるEncoderとCNNによるDecoderで構成されています。

<figure>
<center>
<img src="https://github.com/Project-MONAI/research-contributions/blob/main/SwinUNETR/BRATS21/assets/swin_unetr.png?raw=true" alt="Swin Unetrのモデル構成" width="100%"/>
<figcaption>Swin UNETRのモデル構成</figcaption>
</center>
</figure>

## 事前学習
Swin UNETRの事前学習では複数のタスクで構成されています。
本論文では以下の3つのタスクを採用しており、事前学習の際はそれぞれのTaskむけのHeadをEncoderの後ろに追加します。
- Masked Inpainting (cutout)
- Image Rotation (0, 90, 180, 270の4クラス分類task)
- Contrastive Coding (同じsub-volumeからのサンプル同士の特徴量を近づけ、異なるsub-volumeからのサンプル同士の特徴量は遠ざける)
この3つのタスクのlossの合計をloss関数として学習を行います。

<figure>
<center>
<img src="https://github.com/Project-MONAI/research-contributions/blob/main/SwinUNETR/Pretrain/assets/ssl_swin.png?raw=true" alt="事前学習のフレームワーク" width="50%"/>
<figcaption>事前学習のフレームワーク</figcaption>
</center>
</figure>


# 結論を導くための結果は何か？

著者の実証実験では、5つの公開されているCT画像のデータセットから5050枚のデータセットを作成して事前学習を行っています。
このデータセットで事前学習したモデルを2つのコンペティション (BTCV, MSD) 向けにfine-tuningしています。
BTCV, MSDどちらのコンペティションでもSOTAの精度を達成しています。

また、以下のAblation studyも実施して手法の妥当性を確認しています。
- 事前学習をした場合とscratchの場合の精度比較
- （下流タスクで）使用するアノテーション済み正解データの数を変えての精度検証
- 事前学習に使用するデータ数を変えての精度検証
- 事前学習のタスクの組み合わせを変えての精度検証

# どのような議論がされていたか？
以下のような主張をしています。
- 複数のコンペティションでSOTAを達成したことから手法の妥当性が確認できた
- 事前学習済みのエンコーダーは分類や検出などのタスクにも応用できる
- 提案手法の事前学習はタスクの追加が容易にできる
- 今回はCTのみでの検証で、MRIなど他のドメインの画像についての検証は行っていない

# この研究のメリットデメリットは？
## メリット
- 既存の手法を組み合わせたものなので、比較的簡単に実装、実験ができそうです

## デメリット
- 既存の手法を組み合わせて3D医用画像に適用したのみなので、新しいアイデアという観点での新規性はないといえます
- 事前学習のタスクは何が最適か、いくつ組み合わせるのが良いかわからず、本当に拡張性があるのかは実験してみないとわからないのではと思います
